---
title:  "The motivation: Why even border to learn Machine Learning?"
last_modified_at: 2019-11-01T22:00:02+02:00
redirect_from: "/2019-11-01/IntroML.html"
categories:
  - Blog
header:
  teaser: /assets/blog/2019-11-01/mika-baumeister-Wpnoqo2plFA-unsplash.jpg
---

This post provides a first overview on emerging approaches for ML (machine learning) and the motivation behind learning ML.


# Motivation

<h1>ML is all around us. Starting with</h1>

<p>:chart_with_upwards_trend: Stock market transactions
:credit_card: Credit applications
:mag_right: “Counterterrorism” / Mass surveillance
:couple_with_heart: Dating websites (e.g., hinge, tinder)
:speech_balloon: Natural language processing (NLP), 
:oncoming_automobile: Navigation systems
:pill: Medical applications</p>

![img](/assets/blog/2019-11-01/5Q5OC.png){: .align-center}

During the last decades there has been great progress in ML. NLP (Natural Language Processing), a category of ML, has made substantial [progress](https://ruder.io/tracking-progress-nlp/) in the past years.
Only five years ago the performance in key tasks stagnated and gaining [1pp](https://en.wikipedia.org/wiki/PP_(complexity)) was considered a major success. Today almost all tasks gain +10pp. This is due to deep learning. The training of Deep learning, that is a category of ML, is based on word/sentence/character embeddings. It's models are collections of high dimensional vector spaces and there is no interpretation possible. It's a #'black box'.

![img](/assets/blog/2019-11-01/P1WaO.png){: .align-center}

This tutorial blog is following along a scientific seminar on interpretable machine learning for the DH (Digital Humanities) at the University of Cologne.

## Replacing one machine we don’t understand with another one we don’t understand doesn’t help us
D. Gerstorfer
